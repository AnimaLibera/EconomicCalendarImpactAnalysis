{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Processing</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Importpath</h3>\n",
    "\n",
    "Add Projectfolder to Importpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/avatar/Dokumente/Projekte/Python/EconomicCalendarImpactAnalysis/Code',\n",
       " '/home/avatar/Dokumente/Projekte/Python/EconomicCalendarImpactAnalysis/Notebook',\n",
       " '/home/avatar/.pyenv/versions/3.10.13/lib/python310.zip',\n",
       " '/home/avatar/.pyenv/versions/3.10.13/lib/python3.10',\n",
       " '/home/avatar/.pyenv/versions/3.10.13/lib/python3.10/lib-dynload',\n",
       " '',\n",
       " '/home/avatar/.local/lib/python3.10/site-packages',\n",
       " '/home/avatar/.pyenv/versions/3.10.13/lib/python3.10/site-packages']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "cwd = os.path.abspath(\".\")\n",
    "sys.path.insert(0, cwd.replace(\"Notebook\", \"Code\"))\n",
    "\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Imports</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import fmp\n",
    "import influx as db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Processing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.Timestamp(\"2024-01-01\")\n",
    "stop_date = pd.Timestamp(\"2024-01-07\")\n",
    "\n",
    "FMP = fmp.FinancialModelingPrep(deployment = \"linode\")\n",
    "FMP.economic_calendar_pipeline(start_date, stop_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FMP = fmp.FinancialModelingPrep(deployment = \"linode\")\n",
    "FMP.economic_calendar_pipeline_longrange()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Test new Configuration for InfluxDB</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import influx as db\n",
    "\n",
    "db.InfluxDatabase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Processing: Pricedata form MetaTrader5 CSV's to InfluxDB</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import influx\n",
    "import mt5\n",
    "\n",
    "db = influx.InfluxDatabase(deployment = \"streamlit\")\n",
    "mt5 = mt5.MetaTrader5()\n",
    "\n",
    "majors = [\"AUDUSD\", \"EURUSD\", \"GBPUSD\", \"NZDUSD\", \"USDCAD\", \"USDCHF\", \"USDJPY\"]\n",
    "\n",
    "major = majors[1]\n",
    "\n",
    "print(\"Step #1\")\n",
    "raw_data = mt5.load_csv_to_dataframe(file_name=f\"MetaTrader5 {major} 1MIN Full Year 2023.csv\")\n",
    "print(\"Step #2\")\n",
    "clean_data = mt5.preprocess_csv_dataframe(raw_data, symbol = major, timezone=\"Etc/GMT-2\")\n",
    "\n",
    "print(clean_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step #3\")\n",
    "db.ingest_data(clean_data, mode=\"live\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Quering: InfluxDB Pricedata<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import influx\n",
    "import pandas as pd\n",
    "\n",
    "db = influx.InfluxDatabase()\n",
    "\n",
    "majors = [\"AUDUSD\", \"EURUSD\", \"GBPUSD\", \"NZDUSD\", \"USDCAD\", \"USDCHF\", \"USDJPY\"]\n",
    "major = majors[1]\n",
    "\n",
    "time1 = pd.Timestamp(\"2023-06-23T16:12\")\n",
    "\n",
    "#AUDUSD 2023.06.23\t16:12:00\n",
    "\n",
    "data1 = db.query_data(time = time1, symbol = major, timeframe = \"1min\", source = \"MetaTrader5\")\n",
    "\n",
    "print(data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Trademade API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import provider as pv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider = pv.Provider(deployment = \"local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = pd.Timestamp(\"2024-02-15T13:26\")\n",
    "data = provider.foreign_exchange_rate_trademade(timestamp, \"EURUSD\", \"close\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing: ForexTester.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import influx\n",
    "import wrangler\n",
    "import pandas as pd\n",
    "\n",
    "#db = influx.InfluxDatabase(deployment = \"linode\")\n",
    "source = wrangler.ForexTester()\n",
    "\n",
    "majors = [\"AUDUSD\", \"EURUSD\", \"GBPUSD\", \"NZDUSD\", \"USDCAD\", \"USDCHF\", \"USDJPY\"]\n",
    "\n",
    "major = majors[1]\n",
    "\n",
    "source_name = \"ForexTester.com\"\n",
    "timezone = \"GMT\"\n",
    "timeframe = \"1MIN\"\n",
    "source_file_name = f\"{source_name} {major} {timeframe} {timezone} 2001-01-01 2024-01-31.txt\"\n",
    "sink_file_name = f\"{source_name} {major} {timeframe} Full Year 2023.csv\"\n",
    "start_date = pd.Timestamp(\"2023-01-01\")\n",
    "end_date = pd.Timestamp(\"2024-01-01\")\n",
    "\n",
    "print(\"Step #1 Raw Data\")\n",
    "raw_data = source.load_csv_to_dataframe(file_name=source_file_name)\n",
    "\n",
    "print(\"Strep 1B Short Data\")\n",
    "short_data = raw_data.iloc[7747870:]\n",
    "\n",
    "print(\"Step #2 Intermediate Data\")\n",
    "intermediate_data = source.process_timeframe_csv_dataframe(short_data).loc[start_date:end_date]\n",
    "\n",
    "print(\"Step #3 Sink Data\")\n",
    "source.populate_csv_file(intermediate_data, file_name=sink_file_name)\n",
    "\n",
    "#print(\"Step #3 Clean Data\")\n",
    "#clean_data = source.preprocess_csv_dataframe(intermediate_data, symbol = major, timezone=timezone)\n",
    "\n",
    "#print(clean_data)\n",
    "\n",
    "#print(\"Step #3\")\n",
    "#db.ingest_data(clean_data, mode=\"live\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import influx\n",
    "import wrangler\n",
    "import pandas as pd\n",
    "\n",
    "db = influx.InfluxDatabase(deployment = \"streamlit\")\n",
    "source = wrangler.ForexTester()\n",
    "\n",
    "majors = [\"AUDUSD\", \"EURUSD\", \"GBPUSD\", \"NZDUSD\", \"USDCAD\", \"USDCHF\", \"USDJPY\"]\n",
    "\n",
    "major = majors[1]\n",
    "\n",
    "source_name = \"ForexTester.com\"\n",
    "timezone = \"GMT\"\n",
    "timeframe = \"1MIN\"\n",
    "source_file_name = f\"{source_name} {major} {timeframe} Full Year 2023.csv\"\n",
    "\n",
    "\"ForexTester.com EURUSD 1MIN Full Year 2023.csv\"\n",
    "\n",
    "print(\"Step #1 Raw Data\")\n",
    "raw_data = source.load_csv_to_dataframe(file_name=source_file_name)\n",
    "\n",
    "print(\"Step #2 Clean Data\")\n",
    "clean_data = source.preprocess_csv_dataframe(raw_data, symbol = major, timezone=timezone)\n",
    "\n",
    "print(clean_data)\n",
    "\n",
    "print(\"Step #3\")\n",
    "db.ingest_data(clean_data, mode=\"live\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing: Axiory.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #1 Raw Data\n",
      "Step #2 Clean Data\n",
      "                              open     high      low    close  symbol  \\\n",
      "timestamp                                                               \n",
      "2023-01-02 00:04:00+02:00  1.06962  1.06966  1.06962  1.06962  EURUSD   \n",
      "2023-01-02 00:05:00+02:00  1.06965  1.06998  1.06962  1.06962  EURUSD   \n",
      "2023-01-02 00:06:00+02:00  1.06958  1.06958  1.06958  1.06958  EURUSD   \n",
      "2023-01-02 00:08:00+02:00  1.06962  1.06966  1.06962  1.06966  EURUSD   \n",
      "2023-01-02 00:09:00+02:00  1.06966  1.06966  1.06966  1.06966  EURUSD   \n",
      "...                            ...      ...      ...      ...     ...   \n",
      "2023-12-29 23:53:00+02:00  1.10390  1.10392  1.10383  1.10385  EURUSD   \n",
      "2023-12-29 23:54:00+02:00  1.10383  1.10385  1.10381  1.10385  EURUSD   \n",
      "2023-12-29 23:55:00+02:00  1.10384  1.10389  1.10382  1.10389  EURUSD   \n",
      "2023-12-29 23:56:00+02:00  1.10389  1.10389  1.10364  1.10367  EURUSD   \n",
      "2023-12-29 23:57:00+02:00  1.10366  1.10366  1.10360  1.10360  EURUSD   \n",
      "\n",
      "                          timeframe      source  \n",
      "timestamp                                        \n",
      "2023-01-02 00:04:00+02:00      1min  Axiory.com  \n",
      "2023-01-02 00:05:00+02:00      1min  Axiory.com  \n",
      "2023-01-02 00:06:00+02:00      1min  Axiory.com  \n",
      "2023-01-02 00:08:00+02:00      1min  Axiory.com  \n",
      "2023-01-02 00:09:00+02:00      1min  Axiory.com  \n",
      "...                             ...         ...  \n",
      "2023-12-29 23:53:00+02:00      1min  Axiory.com  \n",
      "2023-12-29 23:54:00+02:00      1min  Axiory.com  \n",
      "2023-12-29 23:55:00+02:00      1min  Axiory.com  \n",
      "2023-12-29 23:56:00+02:00      1min  Axiory.com  \n",
      "2023-12-29 23:57:00+02:00      1min  Axiory.com  \n",
      "\n",
      "[370840 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import influx\n",
    "import wrangler\n",
    "import pandas as pd\n",
    "\n",
    "db = influx.InfluxDatabase(deployment = \"streamlit\")\n",
    "source = wrangler.Axiory()\n",
    "\n",
    "majors = [\"AUDUSD\", \"EURUSD\", \"GBPUSD\", \"NZDUSD\", \"USDCAD\", \"USDCHF\", \"USDJPY\"]\n",
    "\n",
    "major = majors[1]\n",
    "timezone = \"Etc/GMT-2\"\n",
    "\n",
    "print(\"Step #1 Raw Data\")\n",
    "raw_data = source.load_csv_to_dataframe()\n",
    "\n",
    "print(\"Step #2 Clean Data\")\n",
    "clean_data = source.preprocess_csv_dataframe(raw_data, symbol = major, timezone=timezone)\n",
    "\n",
    "print(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #3\n",
      "Counter: 1, Start at: 0, Stop at: 5000\n",
      "Counter: 2, Start at: 5000, Stop at: 10000\n",
      "Counter: 3, Start at: 10000, Stop at: 15000\n",
      "Counter: 4, Start at: 15000, Stop at: 20000\n",
      "Counter: 5, Start at: 20000, Stop at: 25000\n",
      "Counter: 6, Start at: 25000, Stop at: 30000\n",
      "Counter: 7, Start at: 30000, Stop at: 35000\n",
      "Counter: 8, Start at: 35000, Stop at: 40000\n",
      "Counter: 9, Start at: 40000, Stop at: 45000\n",
      "Counter: 10, Start at: 45000, Stop at: 50000\n",
      "Counter: 11, Start at: 50000, Stop at: 55000\n",
      "Counter: 12, Start at: 55000, Stop at: 60000\n",
      "Counter: 13, Start at: 60000, Stop at: 65000\n",
      "Counter: 14, Start at: 65000, Stop at: 70000\n",
      "Counter: 15, Start at: 70000, Stop at: 75000\n",
      "Counter: 16, Start at: 75000, Stop at: 80000\n",
      "Counter: 17, Start at: 80000, Stop at: 85000\n",
      "Counter: 18, Start at: 85000, Stop at: 90000\n",
      "Counter: 19, Start at: 90000, Stop at: 95000\n",
      "Counter: 20, Start at: 95000, Stop at: 100000\n",
      "Counter: 21, Start at: 100000, Stop at: 105000\n",
      "Counter: 22, Start at: 105000, Stop at: 110000\n",
      "Counter: 23, Start at: 110000, Stop at: 115000\n",
      "Counter: 24, Start at: 115000, Stop at: 120000\n",
      "Counter: 25, Start at: 120000, Stop at: 125000\n",
      "Counter: 26, Start at: 125000, Stop at: 130000\n",
      "Counter: 27, Start at: 130000, Stop at: 135000\n",
      "Counter: 28, Start at: 135000, Stop at: 140000\n",
      "Counter: 29, Start at: 140000, Stop at: 145000\n",
      "Counter: 30, Start at: 145000, Stop at: 150000\n",
      "Counter: 31, Start at: 150000, Stop at: 155000\n",
      "Counter: 32, Start at: 155000, Stop at: 160000\n",
      "Counter: 33, Start at: 160000, Stop at: 165000\n",
      "Counter: 34, Start at: 165000, Stop at: 170000\n",
      "Counter: 35, Start at: 170000, Stop at: 175000\n",
      "Counter: 36, Start at: 175000, Stop at: 180000\n",
      "Counter: 37, Start at: 180000, Stop at: 185000\n",
      "Counter: 38, Start at: 185000, Stop at: 190000\n",
      "Counter: 39, Start at: 190000, Stop at: 195000\n",
      "Counter: 40, Start at: 195000, Stop at: 200000\n",
      "Counter: 41, Start at: 200000, Stop at: 205000\n",
      "Counter: 42, Start at: 205000, Stop at: 210000\n",
      "Counter: 43, Start at: 210000, Stop at: 215000\n",
      "Counter: 44, Start at: 215000, Stop at: 220000\n",
      "Counter: 45, Start at: 220000, Stop at: 225000\n",
      "Counter: 46, Start at: 225000, Stop at: 230000\n",
      "Counter: 47, Start at: 230000, Stop at: 235000\n",
      "Counter: 48, Start at: 235000, Stop at: 240000\n",
      "Counter: 49, Start at: 240000, Stop at: 245000\n",
      "Counter: 50, Start at: 245000, Stop at: 250000\n",
      "Counter: 51, Start at: 250000, Stop at: 255000\n",
      "Counter: 52, Start at: 255000, Stop at: 260000\n",
      "Counter: 53, Start at: 260000, Stop at: 265000\n",
      "Counter: 54, Start at: 265000, Stop at: 270000\n",
      "Counter: 55, Start at: 270000, Stop at: 275000\n",
      "Counter: 56, Start at: 275000, Stop at: 280000\n",
      "Counter: 57, Start at: 280000, Stop at: 285000\n",
      "Counter: 58, Start at: 285000, Stop at: 290000\n",
      "Counter: 59, Start at: 290000, Stop at: 295000\n",
      "Counter: 60, Start at: 295000, Stop at: 300000\n",
      "Counter: 61, Start at: 300000, Stop at: 305000\n",
      "Counter: 62, Start at: 305000, Stop at: 310000\n",
      "Counter: 63, Start at: 310000, Stop at: 315000\n",
      "Counter: 64, Start at: 315000, Stop at: 320000\n",
      "Counter: 65, Start at: 320000, Stop at: 325000\n",
      "Counter: 66, Start at: 325000, Stop at: 330000\n",
      "Counter: 67, Start at: 330000, Stop at: 335000\n",
      "Counter: 68, Start at: 335000, Stop at: 340000\n",
      "Counter: 69, Start at: 340000, Stop at: 345000\n",
      "Counter: 70, Start at: 345000, Stop at: 350000\n",
      "Counter: 71, Start at: 350000, Stop at: 355000\n",
      "Counter: 72, Start at: 355000, Stop at: 360000\n",
      "Counter: 73, Start at: 360000, Stop at: 365000\n",
      "Counter: 74, Start at: 365000, Stop at: 370000\n",
      "Counter: 75, Start at: 370000, Stop at: 370840\n"
     ]
    }
   ],
   "source": [
    "print(\"Step #3\")\n",
    "db.ingest_data(clean_data, mode=\"live\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
